\chapter{Conclusions and Recommendations} \label{chap:conclusion}
\section{Conclusion}
In this thesis, we have formulated an AV platooning problem and successfully applied FRL in
a variety of methods to AV platooning. In addition, we proposed new approaches to applying
FRL to AV platoons: Inter-FRL and Intra-FRL.  By comparing FRL performance with both
gradient and weight averaging in the AV platooning scenario, it has been shown that
weight averaging was the optimal aggregation method regardless of using Inter-FRL or
Intra-FRL.  Furthermore, it was found that the Intra-FRLWA strategy was most advantageous
for applying FRL to AV platooning.  Finally, it was proven that applying Intra-FRLWA to
AV platoons up to 5 vehicles in length provided large performance advantages during and
after training when compared to AV platoons that were controlled without FRL. These
results are backed with simulations performed using models trained across four random
seeds, and an additional simulation set with variable platoon sizes.  The focus of this
thesis was on decentralized platoon control, where each follower in the platoon trains
locally with respect to their individual reward.

\section{Recommendations}
In the future, improvements to the system could be made implementing weighted averaging in
the FRL aggregation method. Moreover, in AV platooning communication delays can be
considered in the model to give a more concrete real life example.