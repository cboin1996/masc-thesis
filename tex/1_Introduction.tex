\chapter{Introduction}
\pagenumbering{arabic}
In recent years, federated learning (FL) and it's extension federated reinforcement learning
(FRL) have become a popular topic of discussion in the artificial intelligence (AI)
community.  The concept of FL was first proposed by Google with the development of the
federated averaging (FedAvg) aggregation method \cite{McMahan2016FederatedLO}.
FedAvg was shown to increase the performance of distributed systems while also providing
privacy advantages when compared to using centralized architectures for supervised machine
learning (ML) tasks \cite{Konecny2015, BrendanMcMahan2017a, McMahan2016FederatedLO}.
FL's core ideology was motivated by the need to train ML models from distributed data sets
across mobile devices while minimizing data leakage and network usage
\cite{McMahan2016FederatedLO}.

Research on the topics of reinforcement learning (RL) and deep reinforcement learning (DRL)
have made great progress over the years, however there remain important challenges for
ensuring the stable performance of DRL algorithms in the real world. DRL processes are
often sensitive to small changes in the model space or hyper-parameter space, and as such
the application of a single trained model across similar environments often leads to control
inaccuracies or instability \cite{Yang2019a, Lim2020}.   In order to overcome the
stability challenges that DRL poses, often a model must be manually customized to
accommodate the finite differences amongst similar agents in a distributed system.
FRL aims to overcome the aforementioned issues by allowing agents to share private
information in a secure way.  By utilizing an aggregation method such as FedAvg
\cite{McMahan2016FederatedLO}, systems with many agents can have decreased training
times with increased performance.

Despite the popularity of FL and FRL, at the time of this thesis, there are few works applying FRL to autonomous
driving.  In general there are two types of `models' for AV decision making:
vehicle-following modeling and lane-changing modeling \cite{Ye2019}. For the purposes of
this thesis, the vehicle-following approach known as co-operative adaptive cruise control
(CACC) is explored. Vehicle following models are based on a follower vehicle in a single lane road taking actions
in response to a leader vehicle's actions\cite{Zhu2018}.  CACC is a
multi-vehicle control strategy where vehicles follow one another in a line known as a
platoon, while simultaneously transmitting vehicle data amongst each other \cite{Song2020}.
CACC platoons have been proven to improve traffic flow stability, throughput and safety
for occupants \cite{Song2020, Chu2019b}.  Traditionally controlled vehicle following
models have limited accuracy, poor generalization from a lack of data, and a lack of
adaptive updating \cite{Zhu2018}.

The current state-of-the-art for CACC AV platoons along with previous
works related to FRL are the main motivation for applying FRL to the AV platooning problem. In addition,
an important goal of this thesis is to observe the performance
benefits FRL may have for AV platooning systems.  An FRL framework built atop of a custom AV
platooning environment is designed to analyse FRL's suitability for improving AV platoon performance.
In addition, two approaches are proposed for applying FRL amongst AV platoons. The first proposed
method is Inter-platoon FRL (Inter-FRL), where FRL is applied to AVs across different platoons.
The second proposed method is Intra-platoon FRL (Intra-FRL), where FRL is applied to AVs
within the same platoon.  Furthermore, an investigation is conducted evaluating the performance advantages of
Inter-FRL and Intra-FRL using two aggregation methods: averaging model weights,
and averaging gradients.  Finally, a performance analysis is conducted for
Intra-FRL with weight averaging (Intra-FRLWA) against a platooning environment trained
without FRL (no-FRL).

\section{Objectives}
The main objective of this thesis is to explore FRL's effectiveness in a variety of AV
platooning scenarios, in particular:

\begin{itemize}
    \onehalfspacing
    \item Gain an understanding of the current state-of-the-art for FRL and DRL
    applied to AV platoon control.
    \item Formulate a discretized model of a CACC AV platoon.
    \item Design a MDP platooning environment based on the discretized model of a
    CACC AV platoon, and implement the model in Python3.
    \item Implement a training system for applying the DDPG algorithm to the platooning
    environment, allowing for repeatable DRL experiments to be conducted on the platooning environment.
    \item Implement an evaluation system for the DRL experiments.
    \item Tune any hyperparameters for the DRL model, DDPG algorithm, and platooning environment
    through training cycles.
    \item Scale the system to be able to handle multiple platoons, for $\mathcal{V}$ number of
    vehicles.
    \item Design and implement an FRL algorithm to be applied to the platooning
    environment.
    \item Evaluate the performance of a base case no-FRL AV platooning system in
    comparison with
        \begin{itemize}
            \item Inter-FRL trained using gradients or weights in the aggregation method,
            \item Intra-FRL trained using gradients or weights in the aggregation method.
        \end{itemize}
    \item Identify any performance improvement from using gradients or weights in the
    FRL aggregation method.
    \item Evaluate the performance of Intra-FRLWA versus the no-FRL base case for
    platoons of varying length.
\end{itemize}

\section{Contributions}
To the best of my knowledge, no works at the time of this thesis exist covering the
specific topic of FRL applied to platoon control. Many of the works existing on FRL
have shown the benefits of FRL with regard to increased rate of convergence and overall
system performance with distributed networks, edge caching and communications
\cite{ZhangX2020, LimHyun2021, WangXiaofei2021, Huang2021}.  Furthermore, of the works
cited in this thesis, the works closely related to FRL for platoon control are those of
\cite{Peake2020} and \cite{Liang2019}.  In contrast to \cite{Liang2019}, where FedAvg
is successfully applied to control the steering angle of a single vehicle,
the works of this thesis apply FRL to an AV platooning problem where the control of multiple vehicles' positions and
spacing are required.  \cite{Peake2020} explores multi-agent reinforcement learning
and it's ability to improve the performance of AV platoons experiencing communication delays.
Although \cite{Peake2020} is also successful in their approach, there is no specific
reference to FRL in the paper. In addition, the variety of existing works on FRL
choose to use either gradients or model weights in the FRL aggregation method.
This thesis explores how both aggregation methods can provide benefits to the AV
platooning problem, and most importantly which provides a better result. Finally, this
thesis further distinguishes it's approach from existing literature through declaring two
new possible ways to apply FRL to AV platooning:

\begin{enumerate}
    \item Inter-FRL: where multi-vehicle platoons share data during training across
    platoons amongst vehicles in the exact same platoon position.
    \item Intra-FRL: where multi-vehicle platoons share data during training to increase
    the performance of vehicles within the same platoon.
\end{enumerate}

In contrast to existing literature where it is common to average parameters
across each model in the system, the proposed Intra-FRL architecture includes
a directional averaging where
the first following vehicle does not average it's parameters, and the remaining
followers do. Thus, in Intra-FRL the leading vehicle trains independently of those
following. The AV platoon provides a unique playground environment suitable for
exploring FRL's potential to increase the performance of systems with regard to
convergence rate, and performance.

\section{Organization}
This thesis is divided into the following chapters:

\begin{itemize}
    \item Chapter \ref{chap:background} provides background information on
    topics related to the thesis, introducing autonomous driving, FL, DRL,
    and lastly FRL at a high level. The background information in Chapter
    \ref{chap:background} is intended to to give the reader a high level
    understanding of the topics that follow in each
    chapter of the thesis.
    \vspace{12pt}
    \item Chapter \ref{chap:litreview} provides an in-depth summary of
    the current state-of-the-art research related to FRL and DRL applied
    to AV platooning. The goal of Chapter \ref{chap:litreview} is to
    introduce the state-of-the-art and draw attention to the motivations
    behind the works of this thesis.
    \vspace{12pt}
    \item Chapter \ref{chap:methods} introduces the development of the
    system model, the MDP model, and lastly the DRL model with an
    algorithm implementation of FRL to AV platooning.  The intention of
    Chapter \ref{chap:methods} is to give the reader an understanding of
    the frameworks design and how each component of the overall system
    connects.
    \vspace{12pt}
    \item Chapter \ref{chap:results} presents the experimental
    setup for applying FRL to the AV platooning system, the
    experimental results and a discussion of the results. A comparison of performance for
    no-FRL versus FRL in a variety of AV platooning scenarios with varying
    aggregation methods is provided.
    \vspace{12pt}
    \item Chapter \ref{chap:conclusion} recaps the findings
    from the work presented in this thesis. Recommendations
    are made for future steps to further this research.
\end{itemize}

